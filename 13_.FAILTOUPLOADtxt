computer law & security review 44 (2022) 105659
Available online at www.sciencedirect.com
journal homepage: www.elsevier.com/locate/CLSR
Decrypting Australia’s ‘Anti-Encryption’
legislation: The meaning and effect of the
‘systemic weakness’ limitation
Peter Alexander Earls Davis
Norwegian Research Center for Computer and Law, University of Oslo: Universitetet i Oslo, Oslo, Norway
a r t i c l e i n f o
Keywords:
Encryption
Australia
Going dark
Backdoor
Cybersecurity
a b s t r a c t
The Telecommunications and Other Legislation Amendment (Assistance and Access) Act
2018 is Australia’s latest attempt at solving the ‘going dark’ debate. Yet, like many other
regulatory attempts towards ameliorating the ill-effects of encrypted communications and
information, it has been criticised for privileging law enforcement and intelligence aims
of public safety and security over other interests; particularly privacy and cybersecurity.
Some fear that the new powers facilitate the creation of encryption backdoors that could be
exploited by bad actors. This paper examines the so-called ‘systemic weakness’ limitation,
which was designed to allay these fears. The paper concludes that the limitation is effective
at preventing the most blatant, wholesale encryption backdoors, yet is not a panacea against
all cybersecurity-related concerns that the instrument brings, and its efficacy in practice is
likely to be undermined by its substantive and procedural complexity.
© 2022 Peter Alexander Earls Davis. Published by Elsevier Ltd.
This is an open access article under the CC BY license
(http://creativecommons.org/licenses/by/4.0/)
1. Introduction1
The Australian Telecommunications and Other Legislation Amendment (Assistance and Access) Act 2018 (Cth) (AA Act) is a polarising piece of legislation. From one perspective, it is a draE-mail address: p.a.e.davis@jus.uio.no 1 Work on this paper has been conducted under the aegis of the
project ‘Security in Internet Governance and Networks: Analysing
the Law’ (SIGNAL),funded by the Norwegian Research Council and
UNINETT Norid AS. All references were last accessed 18 November
2021. Thanks go to Ian Walden, Lee Bygrave and reviewers for their
comments on earlier versions of this paper. Nonetheless,the usual
disclaimer applies. All references were last accessed 18 November
2021 unless otherwise stated.
conian2 ‘anti-encryption’3 law that potentially enables Australian agencies to compel companies to ‘build surveillance
backdoors into their encrypted products and services.’4 From
another, it is a measured response to the ‘going dark’ issue
2 UN Special Rapporteur Joseph Cannataci, Submission No 81 to
Parliamentary Joint Committee on Intelligence and Security, Review of the Telecommunications and Other Legislation Amendment (Assistance and Access) Bill 2018 (12 October 2018), 15. 3 David Meyer, ‘Australia Just Passed a Draconian AntiEncryption Bill That Will Create a Headache for Big Tech’
(Fortune, 6 December 2018) <https://fortune.com/2018/12/06/
australia-encryption-law/>. 4 New America, ‘Coalition Raises Serious Concerns About
Australian Draft Bill and Encryption Backdoors’ (New America,
10 September 2018) <https://www.newamerica.org/oti/pressreleases/coalition-raises-serious-concerns-about-australiandraft-bill-and-encryption-backdoors>.
https://doi.org/10.1016/j.clsr.2022.105659
0267-3649/© 2022 Peter Alexander Earls Davis. Published by Elsevier Ltd. This is an open access article under the CC BY license
(http://creativecommons.org/licenses/by/4.0/)
2 computer law & security review 44 (2022) 105659
that ‘does not allow for … the creation of decryption capabilities [or] the implementation of so-called ‘backdoors’.’5
The latter perspective, advanced6 by the AA Act’s creators,
the Department of Home Affairs,7 is derived significantly from
the new section 317ZG8 of the Telecommunications Act 1997
(Cth) (Telecommunications Act) that the AA Act introduces, the
heading of which states that providers ‘must not be requested
or required to implement or build a systemic weakness or systemic vulnerability’.Whilst the new powers that the AA Act introduces under the Telecommunications Act enable the creation
and exploitation of vulnerabilities in technologies that facilitate encrypted communications, taken at face value, the sui
generis section 317ZG precludes more wholesale weaknesses
or vulnerabilities that affect the cybersecurity of more than a
specific target. However, many have cast doubt as to whether
the limitations contained in that provision are sufficient to
prevent the mischief it purports to tackle.9 Indeed, section
317ZG was a major focus of the AA Act’s review by the Independent National Security Legislation Monitor dated 9 July
2020.10 The provision is confusing in both a procedural and
substantive context. A proper understanding of it, though, is
paramount in order to discern how the newly introduced powers balance the various interests (e.g. security, privacy, business freedom) that are invariably at stake when encryption is
regulated.
This paper undertakes the task of ‘decrypting’ the meaning
and effect of section 317ZG and, concomitantly, ponders over
whether or not the Australian approach is a viable blueprint
for other countries to follow. It does this by first introducing
the relevant part of the AA Act, the text of section 317ZG and
the powers that the provision limits in Part 2. Part 3 examines
the material scope of the provision and canvasses possible activities that do or do not fall foul of the limitation, borrowing from historical examples from the ‘going dark’ debate. It
concludes that section 317ZG is an effective limitation against
some of the stronger encryption-busting measures proposed,
5 Department of Home Affairs, ‘Myths about the Assistance and Access Act’ (Home Affairs, 29 August 2019)
<https://www.homeaffairs.gov.au/about-us/our-portfolios/
national-security/lawful-access-telecommunications/
myths-assistance-access-act>; see also Arthur Kopsias, ‘“Going dark”: the unprecedented government measures to access
encrypted data’ [Law Society of New South Wales (Australia)] Law
Society of NSW Journal 74, 75. 6 See e.g. Department of Home Affairs, ‘Assistance and Access:
Industry assistance framework - limitations and safeguards’
(Home Affairs, 17 March 2020) <https://www.homeaffairs.gov.au/
about-us/our-portfolios/national-security/lawful-accesstelecommunications/assistance-and-access-limitationssafeguards>. 7 The AA Bill was first introduced to the House of Representatives
on 20 September 2018 by the Hon Peter Dutton MP,the Minister for
Home Affairs. 8 The full text of this provision is at Part 2.4. 9 For a catalogue of these criticisms, see Parliamentary Joint
Committee on Intelligence and Security, Parliament of the Commonwealth of Australia, Review of the Telecommunications and Other
Legislation Amendment (Assistance and Access) Act 2018 (April 2019),
23-31.
10 James Renwick SC, Trust But Verify: A report concerning the
Telecommunications and Other Legislation Amendment (Assistance and Access) Act 2018 and related matters (2020).
but that the AA Act is far from free of cybersecurity-related
concerns. Part 4 considers broader ramifications of section
317ZG and the AA Act, including whether other jurisdictions
might be inclined to imitate Australia’s novel approach. It
concludes the Australian approach will not be hailed as the
benchmark for a well-considered, proportionate response to
the evidence and intelligence-collecting problems that encryption may cause.
It should also be noted that this paper is primarily aimed
at readers with a knowledge and appreciation of the seemingly interminable ‘going dark’ debate, but without a detailed
understanding of the Australian legal system, with a view to
furthering insight into Australia’s novel approach for those
engaged in the debate abroad. The AA Act has implications
that go far beyond Australia’s borders.11 Given its lack of an
enforceable comprehensive human rights instrument at the
federal level,12 a direct, judicial, rights-based challenge to the
validity of the AA Act, or evidence collected using it, is much
less viable than would otherwise be for Australia’s allies in the
‘global north’. The AA Act could therefore prove a useful ‘backdoor’ for other countries to deal with encryption-related problems they face (particularly their ‘Five Eyes’ allies13), without
having to deal with constitutional issues that might arise if
they tried to enact similar powers themselves.14
2. Industry assistance regime and section
317ZG
2.1. Going dark and its ‘solutions’: a brief primer
The phenomenon of ‘going dark’ or ‘going spotty’ describes
the challenges faced by law enforcement and intelligence
agencies around the world with deciphering encrypted information at rest and in transit.15 Exacerbating these evidence and intelligence-gathering difficulties is the trend,post11 See in particular Monique Mann, Angela Daly and Adam Molnar, ‘Regulatory arbitrage and transnational surveillance: Australia’s extraterritorial assistance to access encrypted communications’ [Alexander von Humboldt Institute for Internet and Society] 9 Internet Policy Review 1 12 Monique Mann and others, ‘The Limits of (Digital) Constitutionalism: Exploring the Privacy-Security (Im)balance in Australia’
80 International Communication Gazette 369, 372. 13 On capability sharing between Five Eyes partners, see
Scarlet Kim and Paulina Perlin, ‘Newly Disclosed NSA Documents Shed Further Light on Five Eyes Alliance’ (LawFare,
25 March 2019) <https://www.lawfareblog.com/newly-disclosednsa-documents-shed-further-light-five-eyes-alliance>. 14 See Mann, Daly and Molnar (n 11). 15 See e.g. Bert-Jaap Koops and Eleni Kosta, ‘Looking for some
light through the lens of “cryptowar” history: Policy options for
law enforcement authorities against “going dark”’ 34 Computer
Law & Security Review 890; Ian Walden, ‘‘The Sky is Falling!’ – Responses to the ‘Going Dark’ problem’ 34 Computer Law & Security Review 1; Harold Abelson and others, ‘Keys Under Doormats:
Mandating Insecurity by Requiring Government Access to all Data
and Communications’ 1 Journal of Cybersecurity 69; Stefan Soesanto, No Middle Ground: Moving on from the Crypto Wars (2018); Stilgherrian, ‘The Encryption Debate in Australia’ (Carnegie Endowment, 30 May 2019) <https://carnegieendowment.org/2019/05/30/
encryption-debate-in-australia-pub-79217>.
computer law & security review 44 (2022) 105659 3
Snowden, of consumer technology companies designing their
encrypted products and services such that the decryption
keys are only available to the end-user(s). As put by Kerr and
Schneier, ‘[f]or government investigators, encryption adds an
extra step: They must figure out a way to access the plaintext
form of a suspect’s encrypted data.’16 This ‘extra step’ is made
more difficult if the company that facilitated the encryption
lacks the technical means to provide immediate decryption
assistance – for instance, if they do not store their end-users’
decryption keys. Described by Rozenshtein as ‘technological
unilateralism’,17 these design decisions are seen by some as
part of broader and deliberate Silicon Valley-led efforts to limit
their involvement in government surveillance activities.18
Possible legal and technical ‘solutions’ to ‘going dark’ issues have been aired out in myriad academic and policy papers.19 These ‘solutions’ involve varying amounts of involvement and cooperation on the part of technology companies
that enable the encryption. Brute-force decryption methods
(i.e. guessing the decryption key20) require little-to-no involvement of the original encryption provider. On the other hand,
the imposition of mandatory encryption backdoors21 or forms
of key escrow22 require that providers have issues of government plaintext access front-of-mind when designing their
encryption implementations.23 As argued herein, the overall rationale of the AA Act is to allow technology companies
free reign to design their products with whichever encryption
methods they wish; but imparts ex post decryption assistance
obligations should the need arise.
Kuehn and McConnell, in a study comparing various ‘going dark’ proposals, label this type of approach as ‘Compelled
Provider Assistance’. For their part, the authors conclude that
‘Compelled assistance should be the preferred technique to
16 Orin S. Kerr and Bruce Schneier, ‘Encryption Workarounds’
[Georgetown University Law Center] 106 Georgetown Law Journal
989, 993. 17 Alan Rozenshtein, ‘Surveillance Intermediaries’ [Stanford Law
School] 70 Stanford Law Review 99, 134ff. 18 E.g. ‘Apple has attempted to design and market its products
to allow technology, rather than the law, to control access to data
which has been found by this Court to be warranted for an important investigation.’ FBI Motion to Compel Apple to Comply with
the Court’s February 16, 2016 Order, 6 in In re Search of an Apple iPhone Seized During the Execution of a Search Warrant on a Black
Lexus IS300, No. 5:16-cm-00010-SP (C.D.Cal. Feb. 25, 2016). See more
broadly ibid; Kristen Eichensehr, ‘Digital Switzerlands’ 167 University of Pennsylvania Law Review 665. 19 Walden, for instance, elicits seven different ‘options’ for plaintext access: see Walden (n 15). 20 Kerr and Schneier, 997ff (n 16). 21 On mandatory backdoor legislation, see Brendan Nixon, ‘The
Case for Mandatory Encryption Backdoor Legislation - Sabotaging
the Right to Privacy or a Necessary Measure to Address the ‘Going
Dark’ Problem?’ CompLex 1. 22 On key escrow, see Bert-Jaap Koops, The Crypto Controversy: A
Key Conflict in the Information Society (Kluwer 1999) 143ff. 23 Kuehn and McConnell describe such design mandates as ‘requir[ing] that providers and manufacturers design, build and deploy products, services and devices with the capability to accommodate future lawful access requests.’ Andreas Kuehn and Bruce
McConnell, Encryption Policy in Democratic Regimes: Finding Convergent Paths and Balanced Solutions (2018), 7.
facilitate lawful access to … encryption products’.24 However,
this conclusion is reached cautiously, with the authors warning that such an approach should be undertaken, inter alia,
‘only with clear rules as to where and to what extent compelled provider assistance is applicable under the legal framework’,25 and that ‘[g]overnments must refrain from policies
and measures that systematically and broadly undermine cybersecurity for all users’.26 Furthermore, the analysis undertaken refrained from analysis of a particular operationalisation of a ‘Compelled Provider Assistance’ regime – in other
words, it was a theoretical, not observational, analysis. One
might regard the present paper, and the AA Act as a whole, as
casting doubt on the theoretical promise identified by Kuehn
and McConnell of the ‘Compelled Provider Assistance’ approach.
2.2. Introduction to the industry assistance regime
The AA Act amends several pieces of Australian legislation in
the areas of criminal law, telecommunications law and laws
relating to surveillance and intelligence.27 According to the
Revised Explanatory Memorandum, the purpose of the Act as
a whole is ‘to introduce measures to better deal with the challenges posed by ubiquitous encryption.’28 The AA Act represents arguably the strongest29 legislatively enacted response
to these challenges by a western democracy since the ‘Crypto
Wars’ of the 1990s.30
The focus of this paper is section 317ZG, inserted by Schedule 1 (of 5 Schedules) of the AA Act into the Telecommunications Act. Section 317ZG falls within the newly created Part
15 of the Telecommunications Act, headed ‘Industry Assistance’.
The powers contained in Part 15 are directed towards addressing the ‘going dark’ problem by enabling certain law enforcement and intelligence agencies31 (hereinafter ‘agencies’) to
24 Ibid, 6. 25 Ibid. 26 Ibid, 38. 27 See AA Act, long title: ‘An Act to amend the law relating to
telecommunications, computer access warrants and search warrants, and for other purposes’. 28 Revised Explanatory Memorandum, Telecommunications and
Other Legislation Amendment (Assistance and Access) Bill 2018,
2.
29 See Stilgherrian, ‘The Encryption Debate in Australia’
(Carnegie, 30 May 2019) <https://carnegieendowment.org/2019/
05/30/encryption-debate-in-australia-pub-79217>. See also US
Attorney General William Barr, ‘Keynote Address’ (International
Conference on Cyber Security, New York, 23 July 2019) <https://
www.justice.gov/opa/speech/attorney-general-william-p-barrdelivers-keynote-address-international-conference-cyber>, noting that ‘many of our international partners such as the UK and
Australia are already moving on statutory frameworks to address’
the going dark issue. 30 On the ‘Crypto Wars’, see Koops (n 22); Stewart Abercrombie Baker and Paul R. Hurst, The Limits of Trust: Cryptography, Governments and Electronic Commerce (Kluwer Law International 1998);
Steven Levy, Crypto: How the Code Rebels Beat the Government - Saving
Privacy in the Digital Age (Viking 2001). 31 These agencies include the Australian Secret Intelligence
Service (ASIS), the Australian Security Intelligence Organisation
(ASIO), the Australian Signal Directorate (ASD) and so-called ‘interception agencies’ (see s 317B), including the Australian Fed-
4 computer law & security review 44 (2022) 105659
engage the assistance of various actors within the telecommunications supply chain, including traditional telecommunications carriage service providers, hardware (including mobile telephone) manufacturers and their suppliers, ‘over the
top’ (OTT) messaging applications and software developers32
(hereinafter ‘providers’) to circumvent or otherwise overcome
encryption. This is done by three newly created instruments,
which certain agency heads can cause the issue of to a designated communications provider:
• Technical assistance request (TAR); a request for technical
assistance on a voluntary basis.
• Technical assistance notice (TAN); a notice requiring the
provider to give technical assistance which it is already capable of giving.
• Technical capability notice (TCN); a notice requiring the
provider to create or implement a new technical capability that would enable the provider to give assistance.33
This paper does not consider TARs in-depth since, whilst
various limitations (including section 317ZG) are placed on
their issuance, compliance with a TAR is voluntary.34 Hence,
a provider seeking to resist a measure asked of them under a
TAR can simply choose not comply.35 Hereinafter, TANs and
TCNs are collectively referred to as ‘notices’.
Notices can only be issued ‘in relation to’ the enforcement
of Australian criminal law, assisting with the enforcement of
foreign criminal law, or for ‘safeguarding national security’.36
For the enforcement of criminal law, notices can only be issued in relation to ‘serious offences’, defined as those ‘punishable by a maximum term of imprisonment of 3 years or
more’.37 Ostensibly, therefore, the industry assistance regime
may only be used towards subject matter of relatively serious
consequence.38
The types of assistance that can be compelled by notices
are listed in section 317E and are referred to as ‘listed acts
eral Police (AFP), the Australian Crime Commission (ACC) and
state/territory level police forces. 32 See Telecommunications Act, s 317C for a full list of ‘designated
communications providers’. 33 For a more comprehensive introduction to the AA Act, see Kopsias (n 5). Note that a ‘TCN’ under the Telecommunications Act is
not the same as under Investigatory Powers Act 2016 (UK) s 253; see
Daniel Severson, ‘The Encryption Debate in Europe’ (Hoover Institution, 21 March 2017) <https://www.hoover.org/sites/default/files/
research/docs/severson_webreadypdf.pdf> 8-11. 34 It is noted, though, that a TAR may nonetheless coerce a
provider into compliance, for fear of a more onerous TAN or TCN. 35 A provider being served with a TAR, however, may come with
it an implicit threat that a TAN or TCN might be served if the TAR
is not complied with. 36 For TANs, Telecommunications Act, s 317L(2)(c); for TCNs, s
317T(3)(c).
37 Telecommunications Act, s 317B (definitions of ‘serious Australian
offence’ and ‘serious foreign offence’). 38 However, the threshold for crimes punishable by maximum 3
years imprisonment is arguably low. For instance,the Criminal Code
Amendment (Sharing of Abhorrent Violent Material) Act 2019 (Cth),
passed in the wake of the Christchurch mosque massacre, imposes a maximum sentence of 3 years imprisonment for failure to
expeditiously remove violent content (Criminal Code Act 1905 (Cth)
Schedule 1, 474.34(9)).
or things’.39 The range of listed acts or things is extensive
and includes providing technical information, installing software, facilitating access to software used for the provision of
an electronic service (i.e. code), and assisting with the testing,
modification or development of a technology or capability.40 In
short, Part 15 gives agencies various options to engage the assistance of private industry where they encounter difficulties
caused by encryption in intelligence or evidence-gathering.
Whereas ‘government hacking’ has been proposed,41 and indeed used,42 by various law enforcement and intelligence
agencies worldwide as a viable option to deal with problems caused by encryption, this is typically done without the
knowledge or assistance of the company that created or owns
the product or system.43 Part 15 of the Telecommunications Act
enables agencies to compel private industry to assist them
with this endeavour. In other words, providers can be compelled to break their own privacy and security measures, or to
help to equip law enforcement and intelligence agencies with
the tools to do so themselves.
2.3. International significance
The scope and importance of Australia’s industry assistance
regime is not purely domestic; it has an international dimension44 in two primary ways. First, the provider that can be
served a notice or request need not have a particularly strong
nexus to Australia or its inhabitants in order to be deemed
a ‘designated communications provider’ under section 317C.
For instance, the term includes a company that ‘(a) develops;
or (b) supplies; or (c) updates; software that is capable of being installed on a computer, or other equipment, that is, or is
likely to be, connected to a telecommunications network in
Australia.’45 Thus, without interpreting the word ‘connected’
in an unreasonably restrictive manner, the notice and request
regime applies extraterritorially.
Second, as aforementioned, notices can be issued for ‘assisting the enforcement of the criminal laws in force in a foreign country, so far as those laws relate to serious foreign offences’.46 This means that on their face, requests and notices
may be issued to a foreign company, for a foreign offence that
has no physical presence in Australia, so long as the provider
meets the definition of ‘designated communications provider’
(including the relatively low threshold of connection to Australia) in section 317C.47
39 For TANs, Telecommunications Act, s 317L(3); for TCNs, s
317T(4)(c)(i). Note additionally ss. 317T(4)(c)(ii),(5), which allow the
Home Affairs minister to legislate more permitted acts or things. 40 Telecommunications Act, s 317E(1). 41 Carlos Liguori, ‘Exploring Lawful Hacking as a Possible Answer
to the "Going Dark" Debate’ Michigan Technology Law Review 317. 42 Ibid. 43 For instance,the Apple vs FBI saga, examined in inter alia in Part
3.2.2, involved a dispute over the extent to which Apple should assist the FBI in unlocking an iPhone. The FBI eventually succeeded
in unlocking the iPhone without Apple’s assistance. 44 See further Mann, Daly and Molnar (n 11). 45 Telecommunications Act, s 317C Item 15. 46 For TARs, Telecommunications Act, s 317G(5)(d)(ii); for TANs: s
317L(2)(c)(ii); for TCNs: s 317T(3)(b). 47 However, the Department of Home Affairs guidance states
that the powers do ‘not allow interception agencies to seek
computer law & security review 44 (2022) 105659 5
A potential third international dimension exists in the area
of capability sharing with other countries. Although Part 15 of
the Telecommunications Act itself is silent on the matter, administrative guidance released by the Department of Home Affairs
notes that ‘[i]t is possible for capabilities developed under Part
15 to be utilised and shared by multiple law enforcement, national security and intelligence agencies across multiple jurisdictions.’48 Whilst this statement is probably directed towards sharing amongst different Australian jurisdictions (i.e.
federal, state or territory),it is conceivable that capability sharing could also be extended to Australia’s intelligence partners,
especially those in the Five Eyes Alliance.49 However, whilst
the industry assistance powers can be used to assist in relation to foreign criminal activities, it does not expressly provide
for assistance with foreign intelligence efforts.50
2.4. Introduction to the systemic weakness/vulnerability
limitation
A recurring criticism of many proposed and enacted legal
measures to overcome the ‘going dark’ problem is that they
tend to disproportionately privilege the desires of agencies
(and, concomitantly, public safety) over individuals’ privacy
and cybersecurity.51 Section 317ZG has a pivotal role in establishing where the privacy/security balance drawn by Part 15
assistance to investigate activity outside of their jurisdiction’:
Department of Home Affairs, ‘Assistance and Access: Administrative Guidance’ (Home Affairs, updated 29 August 2019)
<https://www.homeaffairs.gov.au/nat-security/files/assistanceaccess-administrative-guidance.pdf> 6. 48 Ibid at 15, seemingly referencing the Attorney-General’s powers under s 317S Telecommunications Act to ‘determine procedures
and arrangements relating to requests for technical capability notices’.
49 For sharing between Five Eyes partners, see Scarlet Kim
and Paulina Perlin, ‘Newly Disclosed NSA Documents Shed
Further Light on Five Eyes Alliance’ (LawFare, 25 March
2019) <https://www.lawfareblog.com/newly-disclosed-nsadocuments-shed-further-light-five-eyes-alliance>. 50 See also Home Affairs, ‘Guidance’ (n 47), 15. But also note
Department of Home Affairs, ‘Myths about the Assistance
and Access Act’ (Home Affairs, updated 29 August 2019),
<https://www.homeaffairs.gov.au/about-us/our-portfolios/
national-security/lawful-access-telecommunications/
myths-assistance-access-act>: ‘The industry assistance powers
for intelligence gathering are limited to collecting intelligence
connected with Australia. This is because the Act requires a
geographical nexus between the activities of a company and
Australia. Further, access to content or non-content data through
industry assistance powers requires a valid warrant or authorisation.’ As discussed, however, that ‘geographical nexus’ need not
be particularly strong. 51 See e.g. Lex Gill, Tamir Israel and Christopher Parsons, Shining a Light on the Encryption Debate: A Canadian Field Guide (2018),
iii: ‘These [anti strong encryption] measures are rarely successful in meeting their stated objectives, seriously jeopardize human rights, and regularly entail far-reaching unintended consequences.’ Similar policies and laws have also been criticised as being futile, impracticable or unnecessary: see further Abelson and
others (n 15), 1: ‘These proposals are unworkable in practice, raise
enormous legal and ethical questions, and would undo progress
on security at a time when Internet vulnerabilities are causing extreme economic harm’; Soesanto (n 15).
of the Telecommunications Act, as it limits the powers that the
notice and request regime introduces.
Section 317ZG of the Telecommunications Act is one of three
sections in Division 7 – entitled ‘Limitations’ – of Part 15. Section 317ZG provides a restriction on the industry assistance
regime by prohibiting notices (and TARs) from requesting or
requiring the provider to implement a systemic weakness or
systemic vulnerability. The genesis of the provision is unknown; it lacks an equivalent provision in the Investigatory
Powers Act 2016 (UK), from which the drafters of the AA Act
appear to have drawn inspiration.52 The apparent intention
of the provision is to permit one-off requests or demands for
‘exceptional access’ to plaintext whilst precluding the mandatory insertion of so-called ‘encryption backdoors’ or ‘security
backdoors’ by providers into their products on a wholesale
basis. Certainly, it has been heavily advertised by the Department of Home Affairs as such, with the Department releasing
a web page entitled ‘Assistance and Access: Common myths
and misconceptions’ containing the following passage:
The Assistance and Access Act contains an express prohibition against building or implementing any weakness
or vulnerability in software or physical devices that would
jeopardise the security of innocent users. This is found
in section 317ZG of the Act which also makes clear that any
assistance that makes a system’s encryption or authentication less effective for general users is strictly prohibited.53
Nominally, then, section 317ZG would preclude so-called
‘key escrow’ measures (i.e. where an authorised third party
can access encryption keys) similar to the US Government’s
proposed ‘Clipper Chip’ in the 1990s54 or, for a more recent
example, Ray Ozzie’s ‘Clear’ proposal.55 However, it would
not preclude more targeted approaches such as developing
and exploiting a ‘zero-day’56 on a suspect’s encrypted device,
an encrypted messaging application on that device, or the
provider’s back-end so long as, in each instance, the cybersecurity of non-suspects is unaffected.
52 For instance, the term ‘Technical Capability Notice’ is common
to both the UK and Australian acts,though its meanings are somewhat different across the regimes. See also Home Affairs, ‘Assistance and Access: Common myths and misconceptions’ (n 6): ‘This
legislation comes after the passage of the UK’s Investigatory Powers
Act 2016 and New Zealand’s Telecommunications (Interception Capability and Security) Act 2013, both of which deal with similar subject matter and provide powers to compel assistance from private
companies.’ The AA Act was introduced to Parliament by Peter
Dutton MP, who was then responsible for the Department of Home
Affairs portfolio. 53 Home Affairs, ‘Assistance and Access: Common myths and
misconceptions’ (n 6) (emphasis in original). 54 Michael Froomkin, ‘The Metaphor Is the Key: Cryptography,the
Clipper Chip, and the Constitution’ [University of Pennsylvania
Law School] 143 University of Pennsylvania Law Review 709. 55 Steven Levy, ‘Cracking the Crypto War’ (Wired, 25 April 2018)
<https://www.wired.com/story/crypto-war-clear-encryption/>;
Matthew Green, ‘A few thoughts on Ray Ozzie’s “Clear”
Proposal’ (Cryptography Engineering, 26 April 2018)
<https://blog.cryptographyengineering.com/2018/04/26/
a-few-thoughts-on-ray-ozzies-clear-proposal/>. 56 ‘Zero-days’ are ‘security flaws that are as yet unknown to users
or providers’: Koops and Kosta (n 15), 10.
6 computer law & security review 44 (2022) 105659
The text of both section 317ZG and the definitions of systemic weakness and systemic vulnerability are copied below.
In Australian law, it is established one must insert the full text
of each definition into the substantive text in order to properly construe the provision in question.57 Given that this paper undertakes an interpretative exercise, it would be prudent
to do so here. However, section 317ZG is particularly rife with
definitional shorthand, such that doing so would result in a
lengthy (and somewhat incoherent) text. In such instances, ‘if
the definition as enacted does not fit comfortably into the text,
the exercise of construction will need to address any logical or
grammatical infelicities that arise’.58 Hence,the defined terms
are underlined and explicated where appropriate later on.
317ZG Designated communications provider must not
be requested or required to implement or build a
systemic weakness or systemic vulnerability etc.
(1) A technical assistance request, technical assistance notice or technical capability notice must not have the effect of:
(a) requesting or requiring a designated communications
provider to implement or build a systemic weakness, or a systemic vulnerability, into a form of electronic protection; or
(b) preventing a designated communications provider from
rectifying a systemic weakness, or a systemic vulnerability, in
a form of electronic protection.
(2) The reference in paragraph (1)(a) to implement or build
a systemic weakness, or a systemic vulnerability, into a form
of electronic protection includes a reference to implement or
build a new decryption capability in relation to a form of
electronic protection.
(3) The reference in paragraph (1)(a) to implement or build a
systemic weakness, or a systemic vulnerability, into a form of
electronic protection includes a reference to one or more actions that would render systemic methods of authentication
or encryption less effective.
(4) Subsections (2) and (3) are enacted for the avoidance of
doubt.
(4A) In a case where a weakness is selectively introduced to one or more target technologies that are connected
with a particular person, the reference in paragraph (1)(a)
to implement or build a systemic weakness into a form of
electronic protection includes a reference to any act or thing
that will, or is likely to, jeopardise the security of any information held by any other person.
(4B) In a case where a vulnerability is selectively introduced to one or more target technologies that are connected
with a particular person, the reference in paragraph (1)(a) to
implement or build a systemic vulnerability into a form of
electronic protection includes a reference to any act or thing
that will, or is likely to, jeopardise the security of any information held by any other person.
57 See Privacy Commissioner v Telstra Corporation Limited (2017)
249 FCR 24 at 34, referring to Allianz Australia Insurance Ltd v GSF
Australia Pty Ltd (2005) 221 CLR 568 at 574-575 and Kelly v The
Queen (2004) 218 CLR 216 at 253. 58 Commissioner of Police v Kennedy [2007] NSWCA 328; 5 DDCR 380
at [44]; cited with approval in Tovir Investments Pty Ltd v Waverley
Council [2014] NSWCA 379 at [13].
(4C) For the purposes of subsections (4A) and (4B), an act or
thing will, or is likely to, jeopardise the security of information
if the act or thing creates a material risk that otherwise secure
information can be accessed by an unauthorised third party.
(5) A technical assistance request, technical assistance
notice or technical capability notice has no effect to the extent (if any) to which it would have an effect covered by paragraph (1)(a) or (b).
The definitions of ‘systemic vulnerability’ and ‘systemic
weakness’ are identical but for the words ‘vulnerability’ and
‘weakness’. This paper discusses the distinction between
these terms at Part 3.3. The definition of ‘systemic weakness’
in the Act is as follows:
317B systemic weakness means a weakness that affects a whole class of technology, but does not include
a weakness that is selectively introduced to one or more
target technologies that are connected with a particular person. For this purpose, it is immaterial whether the person can
be identified.
Given the confusing syntax with which the provision is
drafted, it is helpful to reformulate the above provisions in
a more manageable form to assist with understanding the
thrust of section 317ZG as follows (this is done for illustrative purposes, rather than as an exercise that a court would
undertake in interpreting the provision):
• A notice or request has no effect to the extent that it has
the effect of requiring a provider to implement or build a
systemic weakness or vulnerability in a form of electronic
protection.59 This includes, but is not limited to:
◦ a reference to implement or build a new decryption capability;60
◦ a reference to one or more actions that would render
systemic methods of authentication or encryption less
effective;61
• A systemic weakness or vulnerability is a weakness or vulnerability that affects a whole class of technology.62
• However, it does not include a weakness or vulnerability
that is selectively introduced to one or more target technologies that are connected with a particular person,63 unless that action involves any act or thing that will, or is
likely to, jeopardise the security of any information held
by any other person64 (including creating a material risk
that otherwise secure information can be accessed by an
unauthorised third party65);
• A notice or request must also not have the effect of preventing a designated communications provider from rec59 Ibid ss. 317ZG(1)(a),(5). 60 Ibid s 317ZG(2). Note also Telecommunications Act, s 317T(4)(c)(i),
which prohibits TCNs from ‘removing… electronic protection that
are or were applied by, or on behalf of, the provider’. 61 Ibid s 317ZG(3). 62 Ibid s 317B (definitions of ‘systemic weakness’ and ‘systemic
vulnerability’).
63 Ibid. 64 Ibid s 317ZG(4A),(4B). 65 Ibid s 317ZG(4C).
computer law & security review 44 (2022) 105659 7
tifying a systemic weakness or vulnerability in a form of
electronic protection.66
Evidently, even this attempted simplification of section
317ZG cannot overcome the web of inclusions, exclusions, and
exclusions to exclusions that the provision contains.
2.5. Capabilities versus weaknesses and vulnerabilities –
a functional distinction?
It is worthwhile touching on, at this early stage, the somewhat nebulous distinction between capabilities, weaknesses
and vulnerabilities. It seems probable that these terms were
selected for both political and functional purposes. The word
‘capability’ supplies an image of something good, whereas the
words ‘weakness’ and ‘vulnerability’ suggest something bad.
Yet, there is significant overlap between the three; all point, at
least partially, to the actual or potential ability for an entity to
access the plaintext of encrypted information.67
None of the three terms are defined individually; the definitions of ‘systemic weakness’ and ‘systemic vulnerability’ are
focused on the ‘systemic’ aspect, with much left unsaid about
what constitutes a weakness or vulnerability.68 The term ‘capability’ is used throughout the Telecommunications Act in various different contexts. Within Part 15, the term is enigmatic
still. For instance, a TCN must be directed towards (inter alia)
ensuring a provider is capable of ‘giving listed help’69 to an
agency. ‘Listed help’70 points to the list of ‘acts or things’ that a
provider can be forced to undertake under section 317E, which
contain both direct and indirect measures that could assist in
accessing the plaintext of encrypted information. Thus, the
concept of a ‘capability’ could informally be described as a
capability of a provider to assist in accessing plaintext, directly or indirectly.71 A provider could already possess a capability, for which the less procedurally onerous72 TAN could
be used to force the provider to utilise. Conversely, where a
provider does not currently possess a capability, the industry
assistance regime within Part 15 envisions that one can be cre66 Ibid s 317ZG(1)(b). 67 Although not made explicit throughout the operative provisions of Schedule 1 of the AA Act, access to plain text of encrypted
communications is the primary goal as made clear in the Revised
Explanatory Memorandum, Telecommunications and Other Legislation Amendment (Assistance and Access) Bill 2018, 2. 68 See further Part 3.3. 69 Telecommunications Act s 317T(1)(a); note s 317T(1)(b) also uses
the term ‘giving help’. 70 E.g. Telecommunications Act s 317T(4) refers to ‘listed help’ as including the ‘listed acts or things’ enounced in s 317E. 71 Accessing plaintext, rather than decryption, is used here since
a capability could, for instance, be used to access plaintext before
it is encrypted. 72 A TAN can be issued by the Director-General of the Australian
Security Intelligence Organisation (ASIO) or the chief officer of an
interception agency (i.e. the chief of the Australian Federal Police,
the Australian Crime Commission or a State or Territory Police
Force) upon satisfaction of certain decision-making criteria (see
Telecommunications Act, ss. 317 L, 317P). However, a TCN must be issued by the Attorney-General (s 317T(1)) with the approval of the
Minister of Telecommunications (s 317TAAA).
ated and/or implemented by the provider or agency with the
provider’s assistance through the issue of a TCN.
Like capabilities, weaknesses and vulnerabilities could exist already in a provider’s product or system, or be created
in the future. A pre-existing weakness or vulnerability could
be seized upon in order to create a capability, though equally,
the creation of a new capability could create new weaknesses
or vulnerabilities, either as the direct, intended result or as
an unintended side-effect. A weakness or vulnerability may
enable an entity other than the user (whether that be the
provider, agency or third party) to access plaintext. Equally,
however, it may not; a weakness or vulnerability may lead to
some other cybersecurity-related consequence that has little
to do with encrypted information. Hence,the notions of weaknesses and vulnerabilities appear to be somewhat broader
than capabilities.
The above is in no way an exhaustive account of these
terms and concepts, which are discussed and developed further below. However, it is hoped that this generalised description assists the reader in conceptualising these terms as they
appear throughout Part 15 of the Telecommunications Act, and
this paper.
2.6. Section 317ZG in a procedural context
Issues of space regrettably prevent this paper embarking on a
detailed analysis of the procedural context for invoking section 317ZG. The topic is at least as complex as the substantive
aspects of section 317ZG (and perhaps worthy of a follow-up
paper). Regardless, it is worthwhile touching on the more pertinent procedural aspects that affect the ability of providers to
challenge notices on the basis of section 317ZG.
There are two potential fora for a provider to invoke the
systemic weakness limitation, one of which is the more traditional route of judicial review. The other is a process of consultation and assessment, which is available for TCNs (but not
TANs73) by operation of sections 317W and 317WA. Under section 317WA(1), a provider served with a TCN may request an
‘assessment’ by a 2-person panel consisting of a technical expert and a retired judge with at least 5 years’ experience.74
This panel is able to consider, inter alia, ‘whether the proposed
technical capability notice would contravene section 317ZG’,75
and whether the notice is technically feasible, practicable, reasonable and proportionate.76
However, a close look at the provisions indicates that this
review mechanism is not always available. Although per section 317W(1), a TCN ‘must not’ be given unless a consultation
notice has been given to the provider, under s 317WA(1), the
provider may only request an assessment ‘within the time
limit specified in the consultation notice’. This time limit is
stipulated in section 317W(2) as ‘at least 28 days’, however,
this limit is able to be waived – theoretically to no time at all
– if ‘the Attorney-General is satisfied that the technical capa73 A consultation process exists under Telecommunications Act s
317PA, but no assessment is possible. 74 Telecommunications Act s 317WA(2)-(5). 75 Ibid s 317WA(7)(a)(i). 76 Ibid s 317WA(7)(a).
8 computer law & security review 44 (2022) 105659
bility notice should be given as a matter of urgency’77 or if the
28 day time limit is ‘impracticable’.78
In addition, even if the assessors find that the TCN contravenes, for instance, section 317ZG, the Attorney-General is
not bound by that assessment. Rather, the Act merely confers
an obligation on the Attorney-General to ‘have regard to’ the
report.79 Thus, the assessment regime under section 317WA
lack legal ‘punch’ compared to judicial review proper, which
is the second forum from which a provider may seek relief on
the basis of a section 317ZG breach.
Lack of judicial oversight has been a regularly invoked pain
point of the AA Act’s critics.80 Neither TCNs nor TANs follow
the more usual route (for warrants) of having an independent
judicial officer, such as a judge or magistrate,81 issue the instrument upon the application of, for instance, a law enforcement agency. It should be noted, however, that judges that are
conferred with powers to issue warrants under, for instance,
the Telecommunications (Interception and Access) Act 1979 (Cth)
often do so in their capacity as individuals rather than officers of the court in order to avoid issues with the separation
of powers doctrine.82 Thus, the fact that notices are issued
through an administrative procedure – and thus are not subject to ex ante judicial review – is a feature not a bug.
Ex post judicial review is available, however. A lawyer unfamiliar with the Australian legal system may stumble upon the
express exclusion of Part 15 from review under the Administrative Decisions (Judicial Review) Act 1977 (Cth)83 and lead themselves to believe that any judicial review is excluded. However, an ‘entrenched minimum provision of judicial review’84
is necessarily available under the general law since this is not
expressly excluded by the Act.85
As decisions under Part 15 of the Telecommunications Act are
administrative in nature, judicial review is restricted to errors
77 Ibid s 317W(3)(a). 78 Ibid s 317W(3)(b). 79 Ibid s 317WA(11). 80 E.g. UN Special Rapporteur Joseph Cannataci, ‘Submission’ (n
2), 4-6. 81 E.g. Crimes Act 1914 (Cth) s 3E; Telecommunications (Interception
and Access Act) 1979 (Cth) s 39. 82 See LexisNexis, Halsbury’s Laws of Australia, Application procedure [275-3080]; Hilton v Wells (1985) 157 CLR 57 at 66-74 per Gibbs
CJ, Wilson and Dawson JJ; Grollo v Palmer (1995) 184 CLR 348; Simon Bronitt and James Stellios, ’Telecommunications Interception in Australia: Recent Trends and Regulatory Prospects’ (2005)
29 Telecommunications Policy 875, 882-883. 83 Administrative Decisions (Judicial Review) Act 1977 (Cth),
Schedule 1(daaaa). 84 Plaintiff S157/2002 v Commonwealth (2003) 211 CLR 476 at [103]
(Gaudron, McHugh, Gummow, Kirby and Hayne JJ); s 75(v) Australian Constitution. See further Australian Law Reform Commission, ’Judicial Review ’, Traditional Rights and Freedoms - Encroachments by Commonwealth Laws, vol 129 (2016), 413-428. 85 See e.g. Church of Scientology Inc v Woodward (1982) 43 ALR 587
at 598 on whether ASIO was immune from judicial review under
the ASIO Act 1979 (Cth): ‘If Parliament intends to take the radical
step of ousting judicial review then it is reasonable to suppose that
it will express its intention with directness and clarity upon the
topic, thereby taking the responsibility upon its own shoulders for
that result rather than leaving the court to spell it out from a series
of provisions not specifically addressed to that question.’
of law, not fact; no merits review is available.86 That begs the
question of whether a notice’s non-compliance with section
317ZG is a question of fact or of law.Courts are generally reluctant to embark on questions of fact when reviewing administrative decisions, since the administrative body is typically afforded some discretion in its fact-finding. However, where on
its proper construction87 the decision maker’s power is made
conditional on the existence of an objective fact, rather than
simply a discretionary matter that the decision maker must
take into account of, the existence or non-existence88 of that
fact is deemed a justiciable matter.89 Restraints on executive
power of this kind are often called ‘jurisdictional facts’,90 since
the decision-maker lacks jurisdiction to make a decision if the
factual pre-condition is not present.
It is relatively clear that section 317ZG is a jurisdictional
fact and not merely a ‘provision which directs the manner
of the exercise of a power’.91 Section 317ZG(5) states that notices and requests ‘have no effect’ to the extent that they violate section 317ZG(1), indicating that the decision is void regardless of the opinion of the decision-maker. Further, the
provision is worded in mandatory, not discretionary terms:
the heading states that providers ‘must not be requested
or required to implement or build a systemic weakness…
etc.’.92 The word ‘must’ is used in a similar vein in subsection
317ZG(1). Additionally, Division 7 to which section 317ZG belongs is headed ‘Limitations’, signalling a clear demarcation
of the decision-maker’s powers, rather than factors or matters that a decision-maker should have regard to. The consequence is that the decision to issue a notice or request that is
not in compliance of section 317ZG is made ultra vires, and a
86 See Alan Freckelton, ’Judicial Review of Administrative Decisions – General Principles’ in Marianne Dickie (ed), Administrative Decision-Making in Australian Migration Law (The Australian National University 2015) 170. 87 Samsung C & T Corp v Duro Felguera Australia Pty Ltd (2018) 52
WAR 281, 314 per Martin CJ. 88 Per Spigelman CJ in Timbarra Protection Coalition Inc v Ross Mining NL (1999) 46 NSWLR 55 at 63–64, acknowledging that jurisdictional facts can be positive or negative: ‘The parliament can make
any fact a jurisdictional fact, in the relevant sense: that it must
exist in fact (objectivity) and that the legislature intends that the
absence or presence of the fact will invalidate action under the
statute (essentiality)’. 89 As put by Brennan CJ in Project Blue Sky Inc v Australian Broadcasting Authority (1998) 194 CLR 355, 373: ‘[a] provision which directs the manner of the exercise of a power is quite different from
a provision which prescribes an act or the occurrence of an event
as a condition on the power’. 90 As recently affirmed by the High Court in Craig v South Australia (1995) 184 CLR 163 at 177. See also Re Minister for Immigration
and Multicultural Affairs; Ex Parte Applicant S20/2002 (2003) 198 ALR
59 at 73; [2003] HCA 30, [59]. 91 Project Blue Sky Inc v Australian Broadcasting Authority (1998)
194 CLR 355, 373 per Brennan J. 92 Emphasis added. Headings are relevant to construction when
the text of the provision is ambiguous: see Latham CJ in Silk Bros
Pty Ltd v State Electricity Commission of Victoria (1943) 67 CLR 1 at 16.
Also note Acts Interpretation Act 1903 (Cth), s 13(2)(d) stating that
‘any heading to a Chapter, Part, Division or Subdivision’ is part of
the Act.
computer law & security review 44 (2022) 105659 9
provider may seek certiorari93 under the general law in order
to quash the decision to issue the notice.
2.7. Passage of AA Act and history of section 317ZG
It is useful to give some context to the passage of the AA Act
through parliament, since the provision has had several incarnations across various bills. The Telecommunications and Other
Legislation Amendment (Assistance and Access) Bill 2018 (Cth) was
originally released as an exposure draft in August 2018 for
public consultation. A second ‘partially revised’94 version was
released on 20 September 2018.95 The bill eventually passed
on the last sitting day of 2018, December 6, and became law
shortly thereafter, but not before ‘67 pages of amendments
were rushed through in the final hours of debate.’96 Section
317ZG was one of the provisions that was amended at the last
minute, by way of the addition of subsections 317ZG(4A),(4B)
and (4C). The definitions of ‘systemic weakness’ and ‘systemic
vulnerability’,97 which are used exclusively in section 317ZG of
the Telecommunications Act, were also added at this time.
Although these last-minute amendments purport to
strengthen section 317ZG, they doubtless detract from its
interpretive clarity. The opposition Australian Labour Party,
which was promised amendments to the Act in the first parliamentary sitting session of 2019 in return for their support for the Act’s successful passage,98 proposed significant
amendments to section 317ZG and the definitions contained
therein.99 However, as of writing, these have not been enacted
and it remains to be seen if or when these or other amendments100 might be made. A review by the Independent National Security Legislation Monitor and Parliamentary Joint
Committee on Intelligence and Security was delivered to the
93 Certiorari is generally available where ‘[w]herever any body of
persons having legal authority to determine questions affecting
the rights of subjects, and having the duty to act judicially, act
in excess of their legal authority’: R v Electricity Commissioners; Ex
parte London Electricity Joint Committee Co (1920) Ltd [1923] All ER Rep
150; [1924] 1 KB 171; (1924) 39 TLR 715. Prohibition could also theoretically be sought but, given that a challenge is likely to be made
after the notice has been issued (and not, for instance, during the
consultation period), certiorari will likely be the appropriate remedy in most cases. For a recent example of certiorari being ordered
with respect to an evidence-finding tool, see Smethurst v Commissioner of Police [2020] HCA 14. 94 Stilgherrian ‘The Encryption Debate in Australia’ (n 29). 95 See First Reading Speech, Telecommunications and Other Legislation Amendment (Assistance and Access) Bill 2018 (Cth). 96 Stilgherrian, ‘What’s actually in Australia’s encryption laws?
Everything you need to know’ (ZDnet, 10 December 2018) <https://
www.zdnet.com/article/whats-actually-in-australias-encryption
-laws-everything-you-need-to-know/>. 97 Telecommunications Act, s 317B (definitions of ‘systemic weakness’ and ‘systemic vulnerability’). 98 Paul Karp, ‘Labor accuses Coalition of welching on a
deal over encryption bill’ (The Guardian, 12 February 2019)
<https://www.theguardian.com/australia-news/2019/feb/12/
labor-accuses-coalition-of-welching-on-a-deal-over-encryption-bill>. 99 Telecommunications and Other Legislation Amendment (Miscellaneous Amendments) Bill 2019 (Cth). 100 E.g. Telecommunications Amendment (Repairing Assistance
and Access) Bill 2019 (Cth), introduced 4 December 2019.
Attorney-General on 30 June 2020101 and made several recommendations regarding the wording and operation of section 317ZG. These are noted throughout the paper; however,
there is not yet any indication if or when these might be implemented.102
3. Interpreting section 317ZG
3.1. Preliminary remarks and approach to interpretation
Across three rounds of public submissions before the enactment of the AA Act, many critics expressed scepticism that
section 317ZG could deliver on the Department of Home Affairs’ promise that the new Part 15 powers would not be used
to force companies to install encryption backdoors. Criticisms
included those relating its confusing or imprecise drafting,103
the difficulty of squaring the apparent intent behind the provision to its effect in the real world,104 or because it is arguable
that any weakness or vulnerability is by its very nature ‘systemic’.105 Certainly, the novelty of the provision and the powers it seeks to limit, the complexity of subject matter it pertains to, and its rushed amendments make its interpretation
challenging (to say the least). A careful analysis, which this
Part endeavours to provide, is therefore warranted.
As a preliminary remark, it can be observed that section
317ZG applies where a notice or request has the effect of requiring that the provider implement or build a systemic weakness or systemic vulnerability into a form of electronic protection. Therefore, the relevant point of enquiry is the practical
outcome of the notice, not solely its stated objective. A notice
that self-proclaims it is not asking the provider to build or implement a systemic weakness, but the only way of achieving
the demand is to do so, would nonetheless be captured by the
provision.
The analysis below essentially splits the discussion in two.
Part 3.2 discusses the terms ‘build…’, ‘implement’ and ‘electronic protection’. These terms have not been scrutinised
heavily by critics, but have a substantial role in determining the scope of section 317ZG. Indeed, it is concluded that
these terms, as drafted, leave open the door for troublesome
and potentially unintended cybersecurity outcomes of Part 15
101 Renwick SC (n 10). 102 Denham Sadler, ‘No changes to encryption regime this year’
(InnovationAus, 1 December 2020) <https://www.innovationaus.
com/no-changes-to-encryption-regime-this-year/>. 103 See e.g. Communications Alliance et al., ‘Submission to
the Parliamentary Joint Committee on Intelligence and Security (PJCIS) Review of the Telecommunications and Other Legislation Amendment (Assistance and Access) Act 2018, (CommsAlliance, 22 January 2019) < https://www.commsalliance.com.au/
__data/assets/pdf_file/0006/62475/190122_Submission-to-PJCIS_
Assistance-and-Access-Bill-Review-2019_SUBMITTED.pdf> 3-4. 104 See e,g, Vanessa Teague and Chris Culnane, ‘Response
to consultation on Telecommunications and Other Legislation Amendment (Assistance and Access) Bill 2018’ (Home
Affairs, September 2018) < https://www.homeaffairs.gov.au/
how-to-engage-us-subsite/files/assistance-access-bill-2018/
chris-culnane-and-vanessa-teague-university-melbourne.pdf>
3.
105 See PJCIS, ‘April 2019 Review’ (n 9) 29-30.
10 computer law & security review 44 (2022) 105659
of the Telecommunications Act. In Part 3.3, the terms ‘systemic
weakness’ and ‘systemic vulnerability’ themselves are analysed. It is concluded that the key threshold question in future
cases is likely to centre around the systemic aspect; the terms
‘weakness’ and ‘vulnerability’ are essentially self-fulfilling in
all conceivable cases.
The aim of this discussion is to make broad conclusions as
to section 317ZG’s scope, rather than its applicability to certain
plausible scenarios. Regardless, practical examples are used
where expedient to elucidate the possible ramifications of a
given interpretation, including in 3.4, which endeavours to apply the conclusions reached in the foregoing sections to a concrete scenario.
3.2. Implement, build and electronic protection
Section 317ZG does not aspire to be a comprehensive safeguard against the proliferation of vulnerabilities or weaknesses that the industry assistance regime might otherwise
enable. Rather, it only limits what the provider can be forced or
requested to do, and those limits are only on what the provider
can be forced or requested to implement or build into a form
of electronic protection. Thus, it does not limit what an agency
(or private contractor engaged by an agency106) can do themselves. It also does not limit any of the ‘acts or things’ that a
provider can be forced or requested to do that do not involve
the building or implementation of a systemic weakness or
vulnerability into a form of electronic protection. These other
‘acts or things’ include the provision of information about a
provider’s system,107 which could include source code, that
an agency could use to create weaknesses or vulnerabilities
that do not require the cooperation of the provider to operationalise108 – and thus would not be covered by section 317ZG.
The terms ‘build’, ‘implement’ and ‘electronic protection’ evidently have considerable roles to play in shaping the scope of
section 317ZG.
3.2.1. Electronic protection
It is logical to begin with ‘electronic protection’, since this describes the subject matter that must be affected by a notice
for section 317ZG to apply. Nominally, a provider could be required to do something that amounted to the deployment of
a systemic weakness, so long as that weakness is not built or
106 According to a report by Vice, cybersecurity company Azimuth ‘provides Australia essentially all their offensive cyber
capability’, and has previously built capabilities to bypass the
iPhone’s notoriously strong encryption: see Joseph Cox and
Lorenzo Franceschi-Bicchierai, ‘How a Tiny Startup Became the
Most Important Hacking Shop You’ve Never Heard Of’ (Vice,
7 February 2018) <https://www.vice.com/en_us/article/8xdayg/
iphone-zero-days-inside-azimuth-security>. 107 See Telecommunications Act s 317E(1)(b). 108 For instance, Israel-based NSO Group was allegedly able
to assist ‘government spies [to] break into the phones of
roughly 1,400 users across four continents’ through exploiting vulnerabilities in the WhatsApp application: Raphael
Satter and Elisabeth Culliford, ‘WhatsApp sues Israel’s NSO
for allegedly helping spies hack phones around the world’
(Reuters, 29 October 2019) <https://www.reuters.com/article/
us-facebook-cyber-whatsapp-nsogroup-idUSKBN1X82BE>.
implemented ‘into a form of electronic protection’.109 If the
term ‘electronic protection’ is construed narrowly, the scope
of section 317ZG also narrows commensurately.
Per its definition in section 317B, ‘electronic protection includes: (a) authentication; and (b) encryption’. This is an inclusive definition, accordingly ‘reveal[ing] a Parliamentary intention to add to the ordinary meaning of a word a meaning
which is not otherwise within that ordinary meaning or remove doubt that a particular concept or thing falls within the
legislative meaning’.110 Therefore, the definition of electronic
protection is to be construed in the normal way, with the
statutory connotations thereafter included into that meaning.111
The nomenclature ‘electronic protection’ is not common in
the context of encryption or computer security,112 and is thus
not a term of art or a term with a particular trade meaning. Instead, it looks to be borrowed from the Investigatory Powers Act
2016 (UK),113 from which the AA Act seems to have drawn inspiration.114 Its apparent use in the UK instrument is to distinguish the protection of electronic and non-electronic data,115
such as that written on paper. Whilst its use in the Part 15
of the Telecommunications Act may simply be a residual artefact from the inspiration provided by its UK cousin, the reason for choosing ‘electronic protection’ over, for instance, ‘information security’ or ‘data protection’ could be attributed to
the fact that Part 15 of the Telecommunications Act applies also
to telecommunications hardware such as manufacturers of
mobile phone handsets116 and cellular base station towers.117
Hence, whereas the term ‘information security’ could be construed by a court so as to mean the security of information
per se,
118 and not the systems that underlie the processing of
109 Telecommunications Act s 317ZG(1)(a). 110 West Coast Council v Coverdale (No 2) (2015) 325 ALR 751 at
762 per Pearce J referring to Sherritt Gordon Mines Ltd v Federal
Commissioner of Taxation (1976) 10 ALR 441 at 455; see further
Corporate Affairs Commission (SA) v Australian Central Credit
Union (1985) 157 CLR 201 at 206–7. 111 Topfelt Pty Ltd v State Bank of New South Wales Ltd (1993) 120
ALR 155 at 166; Australian Competition and Consumer Commission (ACCC) v Valve Corp (No 3) (2016) 337 ALR 647 at [128]. 112 Interestingly, the term ‘electronic protection’ has been used
by the United States military apparatus in the context of protecting ‘personnel, facilities, and equipment from any effects of
friendly, neutral, or enemy use of the EMS [electromagnetic spectrum]’ during so-called electronic warfare: US Army et al, ‘Electronic Warfare’ (Public Intelligence, 8 February 2012) <https://info.
publicintelligence.net/JCS-EW.pdf> viii. 113 Investigatory Powers Act 2016 (UK) ss. 253(5)(c); 255(4). 114 See fn 53. 115 See Investigatory Powers Act 2016 (UK), s 263(1): ‘“data” includes
data which is not electronic data and any information (whether or
not electronic)’. 116 Telecommunications Act s 317C, Item 10: ‘the person manufactures or supplies customer equipment for use, or likely to be used,
in Australia’. 117 Telecommunications Act s 317C Item 8: ‘the person manufactures
or supplies components for use, or likely to be used, in the manufacture of a facility for use, or likely to be used, in Australia’. 118 This is not to say that ‘information security’ is accepted in legal, technical or policy discourse to be narrowly construed in this
way. On the difficulty of achieving harmonious definitions in the
field of cybersecurity, see Worku Gedefa Urgessa, ‘Multilateral cy-
computer law & security review 44 (2022) 105659 11
that information, ‘electronic protection’ leaves less room for
such a narrow interpretation, and more readily brings, for example, protection against side-channel attacks119 within its
scope. Therefore, it is reasonable to conclude that the term
‘electronic protection’ is intended to be construed broadly so
as to cover any means used to protect data, including encryption, and any means that might directly or indirectly support
the protection of that data, such as a software program that
implements the chosen encryption algorithm or piece of hardware (e.g. fingerprint scanner) that may facilitate decryption.
3.2.2. Build or implement into
Part 15 of the Telecommunications Act empowers agencies to
both require providers to build capabilities themselves into
their products or systems,120 and to provide information and
access to agencies to allow those agencies to build their own
capabilities into the provider’s products or systems.121 Since
TANs can only require providers to give help that they are already capable of giving,122 only TCNs can force a provider to
‘build’ anything, including a capability.
Section 317ZG(1)(a) pertains to the building or implementation of systemic weaknesses/vulnerabilities into a form of
electronic protection. This is distinct from section 317ZG(1)(b),
which prohibits notices that would prevent a provider ‘from
rectifying a systemic weakness, or a systemic vulnerability,
in a form of electronic protection’.123 The choice of disjunctives in and into in these different contexts strongly suggests that the section 317ZG(1)(b) applies to the rectification
of pre-existing weaknesses/vulnerabilities, whereas section
317ZG(1)(a) applies (only) to fresh weaknesses/vulnerabilities
that the notice would be introducing.
This distinction can be illustrated by the prominent dispute between Apple and the FBI that arose from the 2015 San
Bernardino shooting in the US,124 which feverishly reignited
‘crypto-war’ debate in the 21st century. In brief, the FBI could
not unlock a suspect’s iPhone themselves, and Apple could
not immediately provide assistance since neither had access
to the decryption key. The FBI then pressured Apple through
legal means125 to create a special version of iOS (colloquially dubbed ‘FBiOS’) that would allow Apple to unlock the
suspect’s encrypted iPhone at the FBI’s behest. The proposed
work-around could be characterised as aiming to exploit a preexisting weakness or vulnerability in iPhone software, which
bersecurity governance: Divergent conceptualizations and its origin’ (Oxford) [Elseiver] 36 Computer Law and Security Review 1. 119 For a definition of a side-channel attack, see NIST,
‘Side-Channel Attack’ <https://csrc.nist.gov/glossary/term/
Side_Channel_Attack>. 120 See Telecommunications Act s s 317E, especially ss
317E(1)(c),(da),(f),(h),(i),(j).
121 See ibid 317E, especially ss 317E(1)(b),(da),(e),(g). 122 Ibid s 317L(2A). 123 Ibid s 317ZG(1)(b); emphasis added. 124 Scott Shackelford and others, ‘iGovernance: The Future of
Multi-Stakeholder Internet Governance in the Wake of the Apple Encryption Saga’ [University of North Carolina at Chapel Hill
School of Law] 42 North Carolina Journal of International Law and
Commercial Regulation 883, 893ff. 125 Ibid, 894.
was present in all iPhones with the same iOS as the suspect’s
device (and therefore might be considered ‘systemic’).
Putting this into the context of Part 15 of the Telecommunications Act, in this scenario, there are two potential systemic
weaknesses: first, the underlying weakness identified by the
FBI that would allow Apple to bypass the encryption without
the suspect’s key; and second,the so-called FBiOS. The former
weakness would not make section 317ZG(1)(a) applicable as
any notice would not require Apple to implement that weakness into a form of electronic protection; the weakness was already present. However, the consequences that flow from exploitation of that pre-existing weakness to create a capability
would fall within the scope of the ‘implement or build… into’
requirement.
There are several further peculiarities of the
build/implement into requirement worth noting. First, on
the word ‘into’, a provider could (if technically possible)126
be required to build a systemic weakness or vulnerability, so
long as the notice stopped short of requiring that the provider
build the systemic weakness or vulnerability into a form of
electronic protection. For instance, a notice could require a
provider to craft a zero-day vulnerability for an agency, that
the agency could then operationalise themselves, without
further assistance from the provider. Such an outcome might
be perceived as an unintended lacuna within section 317ZG.
However, a further peculiarity, found in subsections
317ZG(2) and (3) of the build/implement into requirement,
mitigates somewhat against this possibility. These subsections include two things within subsection 317ZG(1)(a): a reference to implement or build a new decryption capability, and
a reference to one or more actions that would render systemic methods of authentication or encryption less effective.
Hence, a provider can simply point to the fact that either subsection 317ZG(2) or (3) are satisfied; and avoid any difficulties
related to the implement/build into requirement. Subsections
317ZG(2) and (3) are considered in greater detail in Part 3.3.2.
The ‘build or implement… into’ requirement in subsection
317ZG(1)(a) is therefore incredibly confusing. On one hand,
read in isolation, it significantly restricts the material scope of
subsection 317ZG, such that it only covers notices that require
providers to build systemic weaknesses or vulnerabilities into
their products or services. However, this literal interpretation
is subverted by subsections 317ZG(2) and (3), which include
further subject matter that likely would not be covered by subsection 317ZG(1)(a) on its own.
Still, many conceivable ‘acts or things’ that providers can
be mandated to do can have negative cybersecurity and
privacy-related consequences and yet fall outside of section
317ZG because they do not satisfy the ‘build or implement…
into’ element, nor the further protections granted in subsections 317ZG(2) or (3). One need only look to the ‘listed acts or
things’ in section 317E for an idea of the extensive powers that
section 317ZG does not restrain. Section 317ZG, then, provides
only a limited defence to providers issued with notices requiring them to take actions that might compromise the cybersecurity of their products or systems.
126 Under Telecommunications Act s 317JAA, notices must be technically feasible (though, ironically, this criterion involves the discretion of the decision-maker).
12 computer law & security review 44 (2022) 105659
3.3. Systemic weaknesses and vulnerabilities
3.3.1. Weaknesses and vulnerabilities – a functional distinction?
It is well established in Australian law that ‘a court construing a statutory provision must strive to give meaning to every word of the provision’.127 It would therefore appear curious that INSLM stated in his report that the inclusion of ‘vulnerability’ is ‘redundant’128 – since its very inclusion indicates
that Parliament did not intended it to be. The INSLM’s reasoning was that ‘[t]here is little difference conceptually, in normal
or technical usage, between a “systemic weakness” and “systemic vulnerability”.’129
This paper agrees with the INSLM’s conclusion, but not the
justification provided for it. The inclusion of ‘vulnerability’ is
superfluous because there is no conceivable practical setting
where section 317ZG is atissue, and there is not a weakness (or,
indeed, vulnerability). From a pragmatic perspective, a weakness or vulnerability is an inevitable component of any newly
introduced capability.130 Put simply, an agency will find it difficult to argue that a notice which has the effect of breaking or
circumventing a provider’s cybersecurity protections does not
involve a weakness or vulnerability of some sort.
On an admittedly academic point, though, one can take issue with the INSLM’s characterisation of the terms ‘weakness’
and ‘vulnerability’ as being of ‘little difference conceptually,
in normal or technical usage’. For one, dictionary definitions
characterise a weakness as something more subtle (e.g. ‘slight
fault or defect’131) than a vulnerability (e.g. ‘open to attack’132
or even ‘exposed by a flaw in the cybersecurity system, leaving
it open to attack’133). Documentation from the International
Organisation for Standardisation (ISO),134 the Internet Engineering Task Force (IETF)
135 and Common Weakness Enumeration list (CWE list)
136 support this distinction in the context
127 Project Blue Sky Inc v Australian Broadcasting Authority (1998)
194 CLR 355, [71]; The Commonwealth v Baume (1905) 2 CLR 405,
414.
128 Renwick SC (n 10), 44. 129 Ibid. 130 Ibid 27ff. 131 Macquarie Dictionary (online at 15 February 2021) ‘weakness’. 132 Ibid, ‘vulnerability’. 133 Ibid. 134 ISO/IEC 27000:2012(E) Information Security Management Systems –
Overview and vocabulary at 11 defines a vulnerability as a ‘weakness
of an asset or control that can be exploited by threats’ 135 Internet Engineering Task Force, ‘Internet Security Glossary’
<https://tools.ietf.org/html/rfc2828> defines a vulnerability as a
‘flaw or weakness in a system’s design, implementation or operation and management that could be exploited to violate the system’s security policy.’ 136 The CWE list is a multi-stakeholder-endorsed a multistakeholder-endorsed ‘formal list or dictionary of common software and hardware weaknesses that can occur in architecture, design, code, or implementation that can lead to exploitable security vulnerabilities’: https://cwe.mitre.org/about/faq.html#what_
is_cwe_weakness_meaning; they note that ‘Weaknesses are errors
that can lead to vulnerabilities. A software vulnerability… is a mistake in software that can be directly used by a hacker to gain access to a system or network. A hardware vulnerability is a mistake
in hardware or its firmware that can be used by a hacker to gain
remote or physical access to a system.’ Common Weaknesses Enuof the information security industry. Hence, both the dictionary and technical meanings of the terms point to the sum
of both being intended to cover a wide variety of weaknesses
and vulnerabilities, from the very subtle (i.e. weaknesses) to
the blatant (i.e. vulnerability). From this perspective, there is
logic underlying the inclusion of both.
Whereas establishing the existence of a weakness or vulnerability is, in this paper’s submission, trite, establishing the
existence of a systemic weakness or vulnerability is another
matter. As previously indicated, due predominantly to subsections 317ZG(2) and (3), Part 15 of the Telecommunications Act
separates notices that potentially operationalise 317ZG into
two categories: those that directly affect the integrity of the
encryption method or algorithm, and those that involve some
other work-around (for instance, to bypass the encryption). It
is logical, then, to consider these two alternatives separately.
3.3.2. Don’t touch the crypto - prohibitions relating to encryption and decryption capabilities
Part 15 of the Telecommunications Act treats encryption algorithms as somewhat sacrosanct, privileging means of circumventing them over means of undermining them directly
through what might be considered ‘backdoors’. This is made
apparent in section 317T(4)(c)(i), which prohibits TCNs from
requesting that a provider ‘[r]emov[e] one or more forms of
electronic protection that were applied by, or on behalf of, the
provider’137 Thus, whilst a provider can be required to remove
encryption where they have an existing capability through a
TAN,138 they cannot be asked to remove encryption if they
lack the technical ability to do so through a TCN. This prohibits providers from being ordered to decrypt end-to-end encryption or full-disk encryption to which they do not have the
password, nor any means of knowing the password. In these
circumstances, another ‘act or thing’, would need to be sought
in order to circumvent the encryption applied by the provider.
This approach is reinforced in subsections 317ZG(2) and
(3). The former includes within the prohibition of building or
implementing a systemic weakness/vulnerability ‘a reference
to implement or build a new decryption capability in relation
to a form of electronic protection.’ As aforementioned, ‘electronic protection’ is defined as ‘includ[ing]… (a) authentication and (b) encryption.’ In essence, this section prohibits a
notice from requiring that providers have the ability to decrypt information themselves. For instance, a notice cannot
require a messaging service to stop securing their users’ transmissions with end-to-end encryption, or an operating system
developer to stop offering full-disk encryption. The fact that
section 317ZG(2) omits the word ‘systemic’ is not without significance – a decision-maker issuing a notice could not argue that a decryption capability does not fall foul of section
317ZG because it is only intended to be used for a single user.
Of course, the inference here is that any decryption capability is systemic, since it could be applied in the future to other
meration, ‘Frequently Asked Questions – What is the difference
between a vulnerability and a weakness?’ <https://cwe.mitre.org/
about/faq.html#weakness_vulnerability_difference>. 137 See Telecommunications Act s 317E(1)(a). 138 Ibid.
computer law & security review 44 (2022) 105659 13
users. Section 317ZG(2) therefore puts to rest any worry of a
modernised ‘Clipper Chip’ regime.
Subsection 317ZG(3), provides an overlapping but slightly
different defence against intrusions to providers’ use
of encryption. This includes within the systemic weakness/vulnerability prohibition ‘a reference to one or more
actions that would render systemic methods of authentication or encryption less effective.’ Under this subsection, a
provider could not be forced to modify their ‘systemic’ use
of encryption to something less secure – for instance, to a
lesser key length, weaker algorithm or compromised random
number generator.139 The use of ‘systemic’ here overlaps with
discussion in the next section, but it suffices to say that, if
technically feasible,140 a provider could be made to render an
encryption method less effective for the target of the notice,
so long as it did not affect other users.
One interesting aspect of subsection 317ZG(3) is that the
test is not ‘actions that would render systemic methods of
authentication or encryption insecure’ or similar. Rather, it is
enough that the proposed modification measurably reduces
security – even if the modified product or service, and the information of others, could still objectively be considered secure. For instance, a provider using 4096-bit RSA encryption
could not be required to change to 2048-bit RSA encryption,
despite the latter generally being considered secure by modern standards.141 In a world where cybersecurity experts may
be suspicious of encryption standard-setters, such as NIST,
and their close relationship to security agencies,142 this has
some significance. It is also noteworthy that the subsection
refers to ‘one or more actions’, meaning that one may have
regard to the cumulative effect of several actions, rather than
assessing those actions individually.
In sum, the effect of section 317T(4)(c)(i) is to preclude notices from mandating providers to decrypt where they have
no technical ability to do so. The combined effect of subsections 317ZG(2) and (3) is to expand the meanings of subsection
317ZG(1)(a) where a notice purports to directly undermine or
amend the encryption of a provider’s product to their broader
user-base. As discussed in Part 3.2.2, these provisions avoid
an otherwise narrowly interpretable section 317ZG(1)(a). They
make clear that Part 15 of the Telecommunications Act allows
139 See e.g. Joseph Menn, ‘Exclusive: Secret contract tied
NSA and security industry pioneer’ (Reuters, 20 December
2013) <https://www.reuters.com/article/us-usa-security-rsa/
exclusive-secret-contract-tied-nsa-and-security-industrypioneer-idUSBRE9BJ1C220131220>. 140 Telecommunications Act 317JAA. 141 E.g. Elaine Barker and Qunyh Dang, ‘NIST Special Publication 800-57 Part 3 Revision 1 – Recommendation for Key Management’ (NIST, January 2015) <https://nvlpubs.nist.gov/nistpubs/
SpecialPublications/NIST.SP.800-57Pt3r1.pdf> 11. 142 A report by NIST recently concluded that ‘Suspicions of NSA
intervention in NIST standards in support of the NSA intelligence
mission have a negative effect on NIST’s reputation and the credibility of the standards NIST develops’: NIST Cryptographic Standards and Guidelines Development Process, ‘Report and Recommendations of the Visiting Committee on Advanced Technology
of the National Institute of Standards and Technology’ (NIST, July
2014) <https://www.nist.gov/system/files/documents/2017/05/09/
VCAT-Report-on-NIST-Cryptographic-Standards-and-GuidelinesProcess.pdf> 3.
providers to secure their (and their customers’) products or
information in whatever manner they see fit, and expressly
preclude ex ante encryption design mandates.143
3.3.3. Accessing plaintext without meddling with encryption
Prohibiting direct interference with encryption does not eliminate the possibility of gaining access to plaintext altogether.
From a technical perspective, as is made apparent by a recent lawsuit between WhatsApp and NSO Group,144 it is possible to bypass encryption by exploiting security holes in hardware or software that facilitate the storage or transmission of
encrypted information. Various intelligence and law enforcement agencies internationally have increasingly145 resorted to
these methods, whether themselves or by engaging companies that specialised in doing so. This activity, labelled ‘government hacking’,146 has been cautiously heralded by some
commentators as an uncomfortable truce147 between the two
opposing sides of the ‘going dark’ debate.
Whilst this often occurs unbeknownst to the provider
whose product or service might be surreptitiously examined
for potential exploits by government agencies,148 Part 15 of the
Telecommunications Act coerces providers to assist agencies in
this effort (hence the ‘Compelled Provider Assistance’ label,
described at Part 0). Engaging the assistance of a provider to
find exploits is advantageous for an agency by making it easier,
cheaper and quicker than finding or purchasing and applying
an exploit themselves, as evidenced in the Apple/FBI case (the
FBI revealed that they were later able to decrypt the device
without Apple’s assistance, though with some delay and at
some expense149). The step from pure government hacking, in
which a government agency is placed in a similar position to
a malicious hacker or security researcher,to industry-assisted
capability finding is not without risk, however. Greater access
to the back-end of systems, including powers to modify those
systems, have created fears150 that users’ overall cybersecurity could be compromised by government meddling.
It has been shown above that section 317ZG does succeed
in preventing the imposition of wholesale, ex ante encryptionrelated design mandates on providers.151 However, some have
143 See Kuehn and McConnell (n 23), 7ff. 144 Erik Manukyan, ‘Summary: WhatsApp Suit Against NSO
Group’ (Lawfare, 7 November 2019) <https://www.lawfareblog.
com/summary-whatsapp-suit-against-nso-group>. 145 Koops and Kosta (n 15), 9, noting the ‘quickly rising popularity of hacking powers for law enforcement authorities (and intelligence agencies to the extent they did not have such powers)’; see
further Rozenshtein (n 17). 146 Amie Stepanovich et al., ‘A Human Rights Response
to Government Hacking’ (AccessNow, September 2016)
<https://www.accessnow.org/cms/assets/uploads/2016/09/
GovernmentHackingDoc.pdf>. 147 Koops and Kosta (n 15), 1. 148 For instance,the EternalBlue Microsoft exploit, allegedly leaked
by the NSA in 2017: Lily Hay Newman, ‘The Leaked NSA Spy Tool
That Hacked the World’ (Wired, 3 July 2018) <https://www.wired.
com/story/eternalblue-leaked-nsa-spy-tool-hacked-world/>. 149 Shackelford and others (n 124), 900-901. 150 See PJCIS, ‘April 2019 Review’ (n 9). 151 These mandates might variously be labelled or described as
backdoors, front doors, LEAK (law-enforcement access to keys), or
key escrow.
14 computer law & security review 44 (2022) 105659
doubted whether the targeted ex post approach proclaimed
by proponents of the AA Act works as advertised, in both
a legal and technical sense. There persist fears that section
317ZG might simply be a paper tiger that can be easily overcome by an overzealous agency or creative legal argument. Or,
that section 317ZG, in practical terms, cannot function since
any cybersecurity weakness is, by its nature, systemic.152 As
will be illustrated, these fears are somewhat exaggerated, but
not completely without basis. For reasons that follow, section 317ZG prohibits some of the more egregious actions that
providers could conceivably be forced to undertake in order
to circumvent their encryption controls in a given case. However, the types of activities that section 317ZG does not limit
are nonetheless likely to concern security professionals.
3.3.3.1. Revisiting the definition of section 317ZG Since ‘systemic weakness’ and ‘systemic vulnerability’ are defined
terms, it is useful to both revisit and elaborate upon the
function of definitions within Australian statutes. It is established practice to insert the definition into the text where the
term appears153 and thereafter construe the provision. Further, whilst not defined separately nor appearing in the definitions of systemic weakness/vulnerability, the term systemic
‘is part of the material which can be used to construe the definition’.154
Therefore, in construing the meaning of section 317ZG(1)(a)
of the Telecommunications Act, a court would lay out the statute
in a manner such as the following:
(1) a [request or notice] must not have the effect of:
a. requesting or requiring a designated communications
provider to implement or build a [systemic weakness]
a weakness that affects a whole class of technology, but
does not include a weakness that is selectively introduced to one or more target technologies that are connected with a particular person. For this purpose, it is
immaterial whether the person can be identified.
…into a form of electronic protection;
3.3.3.2. ‘Class of technology’ It is apparent from the above
definition that the concept of a ‘whole class of technology’ is
of critical importance in understanding what is meant by a
systemic weakness or vulnerability. The phrase is not defined
in the Telecommunications Act, nor is it a term of art within the
field of information security or telecommunications, leading
some critics155 to suggest that, if interpreted restrictively, it
could permit the use of vulnerabilities that affect people other
than the ‘particular person’ that is the target of the notice.
For instance, consider that an agency wishes to decrypt a suspect’s iPhone X running iOS 12.4.1. A notice is issued to require
152 See PJCIS, ‘April 2019 Review’ (n 9), 27ff. 153 See (n 57). 154 Birmingham City Council v Walker [2007] 2 AC 262 at [11] per Lord
Hoffman. It should, however, be noted that this is now always the
case, as discussed in Tovir Investments Pty Ltd v Waverley Council
[2014] NSWCA 379 at [20]-[21]. 155 PJCIS, ‘April 2019 Review’ (n 9), 26-27.
Apple to update all iPhones running iOS 12.4.1 immediately to
a software version that contains a capability that necessarily
weakens the security ofthese iPhones (i.e.itis established that
this would implement a weakness).Whether or not this notice
would be unlawful depends on whether the weakness is applied to a ‘class of technology’. The agency issuing the notice
could argue that the ‘class of technology’ is not iPhones running iOS 12.4.1, but iPhones or even mobile phones in general.
Since the notice does not affect the whole class of technology,
but only a subset of it, it can be argued the weakness being
implemented would not be ‘systemic’.
Determining whether ‘class of technology’ is properly construed in this way is a matter of statutory interpretation. Under Australian law, ‘[t]he primary object of statutory construction is to construe the relevant provision so that it is consistent with the language and purpose of all the provisions of the
statute’,156 considered as a whole.157 Determining the meaning of a provision in light the over 1000-page Telecommunications Act, and over 200-page AA Act that (in part) amends it158
appears an impossible task. But, as put as put by former High
Court Chief Justice Gleeson (writing extra-judicially), ‘[i]n order that the purpose of a legislative provision may be used
rationally to elucidate the meaning of the provision, it may be
necessary to identify a purpose accurately and at an appropriate level of specificity’.159 And, as Justice Middleton (also writing extra-judicially) assures us, this task is ‘mostly common
sense’.160
In the present case, it is argued that the purpose of the industry assistance regime in the newly created Part 15 of the
Telecommunications Act is to enable targeted and specific technical assistance by providers. The purpose of section 317ZG to
limit the scope of such notices and requests so as to protect
innocent third parties from suffering negative consequences
to their information security. This is apparent, inter alia, from
subsections 317ZG(4A)-(4C), which refer to ‘jeopardis[ing] the
security of any information held by any other person’ and
‘creat[ing] a material risk that otherwise secure information
can be accessed by an unauthorised third party’. It is further apparent from the concept of ‘target technologies… connected with a particular person’ that is part of the definitions
of systemic weakness/vulnerability and, indeed,the term ‘systemic’ itself. An unduly restrictive interpretation of ‘class of
technology’ would be repugnant to that purpose – and common sense – by permitting an agency to justify any number of
156 Project Blue Sky Inc v Australian Broadcasting Authority (1998)
194 CLR 355 at [69]; Acts Interpretation 1901 (Cth) s 15AA. 157 Cooper Brookes (Wollongong) Pty Ltd v Federal Commissioner
of Taxation (1981) 147 CLR 297 at 320. 158 As put in Commissioner of Stamps (SA) v Telegraph Investment Co
Pty Ltd [1995] HCA 44; 184 CLR 453 at [14], referencing s 11B of the
Acts Interpretation Act 1901 (Cth), ‘both the Act which is amended
and the amending Act are to be read together as a combined statement of the will of the legislature’. 159 Murray Gleeson, ‘Statutory Interpretation’ <https://www.
hcourt.gov.au/assets/publications/speeches/former-justices/
gleesoncj/gleeson11mar09.pdf> 12. 160 John Middleton, ‘Statutory interpretation: Mostly common
sense?’ [University of Melbourne] 40 Melbourne University Law Review 626.
computer law & security review 44 (2022) 105659 15
measures so long as they can conjure a ‘class of technology’
at a higher level of abstraction than that sought.
Support for this view can be found in the Revised Explanatory Memorandum. On this matter, the Revised Explanatory
Memorandum states:
‘Technological classes include particular mobile device
models carriage services, electronic services or software.
The term is intended to encompass both old and new technology or a subclass within a broader class of technology;
for example an iOS mobile operating system within a particular class, or classes, of mobile devices. Where requirements in a notice make the whole set of these items more
vulnerable, it will be prohibited. This ensures that the powers do not jeopardise the general use of technology by persons who are not of interest to law enforcement and security agencies.’161
Australian courts are slower to refer to extrinsic materials
like explanatory memoranda than,for instance, European civil
law countries. As put by McHugh J, ‘[e]ven if extrinsic material
convincingly indicates the evil at which a section was aimed,
it does not follow that the language of the section will always
permit a construction that will remedy that evil.’162 Section
15AB of the Acts Interpretation Act 1901 (Cth), however, permits
recourse to extrinsic material, inter alia, ‘(1)(b) to determine
the meaning of the provision when: (i) the provision is ambiguous or obscure’.
The Explanatory Memorandum, then, lends further support to the conclusion that an overly restrictive interpretation would not be tenable. The key point of enquiry, according to the Revised Explanatory Memorandum, is whether the
notice would adversely affect those that are not the targets of
a notice. Therefore, the concept is both broad and flexible. In
the given example, a ‘class of technology’ could be all mobile
phones, all iPhones, all iPhone Xs, all iPhone Xs running iOS
12.4.1, or even something more specific (e.g. all iPhone Xs sold
in a particular area); a notice is only lawful if a created weakness or vulnerability affects only the person who is the subject of it. Put differently, the Revised Explanatory Memorandum suggests that ‘affect[ing] a whole class of technology’, in
essence, means (a weakness) ‘affecting any other person than
the target person’. From the foregoing, it would be difficult for
an agency to argue otherwise.
3.3.3.3. Prohibitions against jeopardising information security
of 3rd parties There is one final matter to discuss before tying
this Part’s discussion together. That is subsections 317ZG(4A)-
(4C), which were touched on earlier. These subsections pertain
to ‘a reference to any act or thing that will, or is likely to, jeopardise the security of any information held by any other person.’ Subsection 317ZG(4C) includes within the meanings of
subsections 317ZG(4A) and (4B) ‘an act or thing creates a material risk that otherwise secure information can be accessed
by an unauthorised third party’. It is tempting to view these
161 Revised Explanatory Memorandum, Telecommunications and
Other Legislation Amendment (Assistance and Access) Bill 2018,
36-37.
162 Newcastle City Council v GIO General Ltd (1997) 191 CLR 85 at
113.
provisions as catch-all provisions precluding any capability
that could affect the information security of an innocent third
party. Indeed, this is how the Revised Explanatory Memorandum envisages the operation of these provisions:
‘The effect of new subsections 317ZG(4A) to (4C) is to enhance the protections against systemic weakness or vulnerabilities by making clear that industry assistance cannot be requested or required if it would, or would be likely,
to jeopardise the security of any information held by a person other than a person connected with a target technology, including if the act or thing or requested or required
would create a material risk that otherwise secure information can be accessed by an unauthorised third party.’163
However, once one has untangled their confusing syntax,
their function appears much more modest. These subsections
only apply ‘[i]n a case where a weakness is selectively introduced to one or more target technologies that are connected
with a particular person’164 In effect, they operate to clarify
that a weakness or vulnerability ‘that is selectively introduced
to one or more target technologies’165 may still be systemic. As
an example, a capability in the form of a piece of malware uploaded to a suspect’s computer may be intended for that single target technology, but if it is able to infect other devices166
and thus ‘jeopardise the security of information’ held on those
devices, then that weakness or vulnerability is systemic provided such a scenario is ‘likely’.
Hence, by their wording, subsections 317ZG(4A)-(4C) do not
completely exclude the possibility of a weakness that might
affect the security of a non-suspect’s information. However,
to repeat the observation made in Part 3.3.3.2, they can be argued as indicative of the overall intention of section 317ZG to
protect against such events.
In sum, then, this paper concludes that the term ‘systemic’, when read in light of the various subsections of section 317ZG, probably pertains to any weakness or vulnerability that affects an innocent third party. Presuming that this
is indeed the correct interpretation, then it begs the question of why the statute does not state this more explicitly. The
absence of parliamentary debate on the last-minute amendments, of which 317ZG(4A)-(4C) were part, may be to blame.
Amendments tabled by the Labour Government on 14 February 2019167 would have gone some way in doing so, and recommendations from the INSLM would assist in this regard if
implemented168 – though in a less elegant manner.
163 Revised Explanatory Memorandum, Telecommunications and
Other Legislation Amendment (Assistance and Access) Bill 2018,
99.
164 Telecommunications Act, s 317ZG(4A). 165 Ibid s 317B (definitions of ‘systemic weakness’ and ‘systemic
vulnerability’).
166 E.g. a computer worm, such as the Stuxnet worm allegedly
used to infect Iranian uranium enrichment facilities. See Kim
Zetter, ‘An Unprecedented Look at Stuxnet, the World’s First Digital Weapon’ (Wired, 11 March 2014) <https://www.wired.com/2014/
11/countdown-to-zero-day-stuxnet/>. 167 Telecommunications and Other Legislation Amendment (Miscellaneous Amendments) Bill 2019 (Cth). 168 Renwick SC (n 10), 44.
16 computer law & security review 44 (2022) 105659
3.4. Applying section 317ZG to GCHQ’s ‘Ghost protocol’
On close examination, section 317ZG, though cumbersome,
does genuinely limit certain undesirable acts or things that a
provider can be required to do. Four main points bear repeating in this regard. First, section 317ZG only operates to limit
what a provider can be requested or required to build or implement into a form of electronic protection. As has been argued
by critics, the mere fact that a new weakness or vulnerability has been created through the industry assistance regime,
and could be used again (by Australian authorities, Five Eyes
members or bad actors that somehow obtain it) does not necessarily breach section 317ZG. It is therefore not a panacea
against all cybersecurity-related concerns with the AA Act.
Secondly, whereas computer security experts may argue that
an agency meddling with a provider’s cybersecurity controls
will inevitably lead to weakness or vulnerabilities, this fact
alone is not enough to invoke section 317ZG. Thirdly, the provision effectively places direct interference with the encryption used by providers off-limits. The AA Act does not mandate wholesale encryption backdoors. Fourthly, the provision
is successful in restricting the introduction of security weaknesses and vulnerabilities to a target technology, placing some
emphasis on protecting the information security of third parties, if clumsily so. Given the extensive powers that remain
outside of the limitation, however, both critics and providers
are unlikely to find much comfort in this finding.
It is useful to place the conclusions reached in this part in
context with a real-world example. Given that this paper has
used an example of data at rest (i.e. the FBiOS saga) an example of how section 317ZG may operate in the context of data in
transit may paint a fuller picture. Perhaps the most prominent
example is GCHQ’s ‘Ghost Protocol’, which refers to a blog post
in late 2018 by GCHQ representatives proposing to allow lawful
access to end-to-end encrypted messaging services by giving
agencies the ability to add a ‘ghost’ user to conversations, and
supressing a notification that the new user had been added.169
The blog post does not make reference to a particular messaging service, but popular messaging services with end-to-end
capabilities such as WhatsApp, Signal and Telegram are obvious targets.
Whether a ‘Ghost Protocol’ would contravene section
317ZG depends on the technological features of the encrypted
messaging service, and therefore the type of capability that
would be required to insert the ‘ghost’ user. For instance, if
a ghost user could be targeted towards a single user without
changing the underlying architecture of the messaging service as a whole – a digital analogy to placing ‘crocodile clips’
on copper phone lines, as the GCHQ authors claim170 – there
are likely no issues with section 317ZG. It is true that creating
the capability to insert a ghost user may itself be perceived
as a weakness – even a systemic one, particularly if it ended
up in the wrong hands or was otherwise abused. But recall
that a critical threshold question is whether a systemic weak169 Ian Levy and Crispin Robinson, ‘Principles for a
More Informed Exceptional Access Debate’ (Lawfare,
29 November 2018) <https://www.lawfareblog.com/
principles-more-informed-exceptional-access-debate>. 170 Ibid.
ness/vulnerability is built or implemented into a form of electronic
protection. In the present example, nothing is built or implemented in a systemic manner; it is able to be targeted to a
single messaging conversation.
Of course, the ‘crocodile clip’ analogy oversimplifies the
technological component of adding a ghost user to a conversation.171 If this can only be done by modifying the encryption algorithm, this would automatically be excluded under
section 317T(4)(c)(i) and subsections 317ZG(2) and (3). Hence,
any circumvention of end-to-end encryption through the new
AA Act powers is likely only permissible at the end-points,172
not in transit (as the GCHQ proposal suggests). Even if some
technique could be applied that avoids changes to the method
of encryption, if it must be applied to more users than the target (such as an application update to all users) it would almost
certainly fall foul of section 317ZG on the interpretation of systemic weakness/vulnerability discussed above. In any event, a
provider of an encrypted messaging service that is capable of
providing ‘crocodile clip’/ghost user assistance to an agency
may also be tempted to patch that capability once made aware
of it, which it cannot be coerced against doing by way of subsection 317ZG(1)(b).
4. Concluding remarks
This paper has concluded – albeit cautiously – that section
317ZG is more than mere disingenuous lip service to privacy
and pro-encryption advocates. After some untangling, the innovative and sui generis systemic weakness/vulnerability limitation appears to succeed in preventing agencies from mandating providers implement encryption backdoors and wholesale cybersecurity weaknesses to their products.
However, this paper also prompts questions over whether
the industry assistance regime is desirable or even useful.
According to one report, after the passing of the AA Act, ‘[t]
he New South Wales police officer in charge of enforcing the
federal government’s controversial encryption laws’ stated ‘“I
haven’t got a clue how to implement it”’,173 despite having
himself written a paper on the new powers published in a legal journal.174 As indicated by Stilgherrian in a Carnegie Endowment report, as of August 2020 only a few dozen voluntary
171 Sharon Bradford Franklin, Andi Wilson Thompson, ‘Open
Letter to GCHQ on the Threats Posed by the Ghost Proposal’ (Lawfare, 30 May 2019) < https://www.lawfareblog.com/
open-letter-gchq-threats-posed-ghost-proposal>; see also Peter
Swire, ‘From Real-Time Intercepts to Stored Records: Why Encryption Drives the Government to Seek Access to the Cloud’ 2 International Data Privacy Law 200. 172 On vulnerabilities on encrypted smartphones, see Maximilian
Zinkus, Tushar Jois, and Matthew Green, ‘Data Security on Mobile
Devices: Current State of the Art, Open Problems, and Proposed Solutions’ (SecurePhones, 18 November 2020) <https://securephones.
io/main.html>. 173 Bo Seo, ‘Top cop ’hasn’t a clue’ how to police encryption laws,
slams lack of consultation’ (AFR, 11 March 2019) <https://www.afr.
com/technology/top-cop-hasnt-a-clue-how-to-policeencryption-laws-slams-lack-of-consultation-20190304-h1byw6>. 174 See Kopsias (n 5).
computer law & security review 44 (2022) 105659 17
TARs appear to have been issued country-wide, and ‘there has
been no reported use of a TCN.’175
The style of the industry assistance regime – in terms of
its volume of complexity – is emblematic of Australia’s legislative approach to national security legislative law more
broadly.This was identified in a 2019 report on the legal framework of Australia’s National intelligence community, which
was critical of some of the ‘unnecessary complexity’ and
‘sheer volume’ of the regime.176 As the report further identifies, ’[c]omplex laws also undermine public trust and confidence.’177 The complexity of the AA Act has had an impact on
Australia’s digital business sector, with a 2021 report observing that ‘the nature and limits of these [AA Act] powers are
subject to significant uncertainty’,178 contributing to an overall finding that:
‘[The AA Act] has the potential to result in significant economic
harm for the Australian economy and produce negative spillovers
that will amplify that harm globally. By significant, we mean
economic harms measurable in the multiple billions of dollars that are broad-based and likely to be (primarily) realised in coming years.’179
Thus, if other jurisdictions are looking to the AA Act for inspiration, they are best advised to come to a clearer and more
elegant solution – lest they bring negative effects to their digital economies.
More generally, the analysis in this article might point
to more fundamental difficulties with so-called ‘Compulsory
Industry Assistance’180 regimes as solutions to the ‘going
dark’ debate. The idea of engaging industry assistance for
the purpose of accessing plaintext from encryption is, at face
value, appealing. Traditional telecommunications providers
have, essentially since their inception, been subject to obligations to provide certain levels of assistance to law enforcement and intelligence agencies worldwide. In an age of encrypted communications, applying these same principles to
providers of encrypted information services seems entirely
reasonable. However, the increased technical complexity and
inter-connectedness of products and services means that the
analogy of ‘digital crocodile clips’ is oversimplified, despite
what GCHQ representatives might argue. The AA Act may
be taken as evidence that constructing a coherent statutory
framework that appropriately balances the interests of stakeholders (e.g. providers, agencies, end-users) lies somewhere
between difficult and impossible in practice.
175 Stilgherrian, ‘The Encryption Debate in Australia: 2021 Update’
(Carnegie, 31 March 2021) <https://carnegieendowment.org/2021/
03/31/encryption-debate-in-australia-2021-update-pub-84237>. 176 Dennis Richardson AC, Comprehensive Review of the Legal
Framework of the National Intelligence Community, Vol 1 (2019),
33.
177 Ibid. 178 George Barker and others, The Economic Impact of Laws that
Weaken Encryption (2021), 13. 179 Ibid, 4 (emphasis in original). 180 See Part 2.1.
As a final remark, one can also speculate from the findings
herein as to how the new Part 15 powers might change how
providers behave with regards to their cybersecurity and use
of strong encryption. On one hand, providers are incentivised
to strengthen the cybersecurity of their products, through inter alia the use of end-to-end or full disk encryption that only
the end-user(s) can decrypt. It certainly seems possible for a
provider to design their products and systems in such a way
as to be resistant to lawful tampering through a TCN or TAN.
In this way, the new powers may have the opposite effect as
desired, hardening the resolve and cybersecurity of providers,
particularly those who have an incentive to project a prosecurity and privacy or anti-authority image.181
On the other hand, providers without the willpower or warchest to challenge the issuance of notices or requests may
be faced with the opposing incentive. It is simply easier for
a provider not to offer products and services that preclude
the provider (and, by extension, agencies) from accessing the
plaintext of encrypted information. An overall chilling effect
on individual privacy and cybersecurity is the result.
Overall, the extreme complexity of both the substantive
and procedural aspects of a single section within a 228-page
amending act (i.e. the AA Act) is illustrative of the political, legal and technical challenges associated with the going dark
issue as a whole. In the nearly three years since its passage,
no country is yet to embrace Australia’s approach. Focus in
the global north has seemingly shifted to intermediary liability (e.g. under section 230 of the US Communications Decency Act
1996). Whilst imposing provider liability for users’ encrypted
communications is not without its own considerable difficulties, the proposed legal instruments (e.g. the US Eliminating
Abusive and Rampant Neglect of Interactive Technologies Act of
2020 (US) (EARN IT Act)) are, at the very least, considerably easier to digest and interpret than the verbose AA Act.
Declaration of Competing Interest
The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.
Data Availability
No data was used for the research described in the article.
181 On this topic, see Rozenshtein (n 17).